{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3P5Xo5URiU2f"
   },
   "outputs": [],
   "source": [
    "#main.py\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms as T\n",
    "from datasets.image_dataset import ImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from models.customNN import FirstAttemptFCN, Model\n",
    "import  torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from uuid import uuid4\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "#prepare Dataset\n",
    "\n",
    "\n",
    "\n",
    "#Modelling\n",
    "\n",
    "#Training\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SEED= 42\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    #create folder\n",
    "    # folder_name= f\"run-{str(uuid4())[:8]}\" #unique num\n",
    "    #get the current date and time\n",
    "    dt=datetime.now()\n",
    "    #fromat the d/t with custom separators\n",
    "    f_dt= dt.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    folder_name= f\"run-{f_dt}\"\n",
    "    os.mkdir(f\"artifacts/{folder_name}\")\n",
    "\n",
    "    #create a tensorboard writer\n",
    "    writer= SummaryWriter(log_dir=f\"artifacts/{folder_name}/tensorflow_logs\")\n",
    "\n",
    "\n",
    "    train_csv_path=r'data\\train.csv'\n",
    "    val_csv_path=r'data\\test.csv'\n",
    "    BATCH_SIZE= 4\n",
    "    transfroms= T.Compose(\n",
    "        [\n",
    "            T.Resize((256,256)),\n",
    "            T.ToTensor()\n",
    "        ]\n",
    "    )\n",
    "    train_dataset=ImageDataset(train_csv_path, transforms=transfroms)\n",
    "    train_data_loader= DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_dataset=ImageDataset(val_csv_path, transforms=transfroms)\n",
    "    val_data_loader= DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "\n",
    "    model= FirstAttemptFCN(img_size=256, num_channels=3,num_labels=5)\n",
    "\n",
    "    #train\n",
    "    LR = 0.001\n",
    "    EPOCHS= 15\n",
    "    MIN_EPOCH=5\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    epochwise_train_losses=[]\n",
    "    epochwise_val_losses=[]\n",
    "    epochwise_val_acc=[]\n",
    "    epochwise_train_acc=[]\n",
    "    best_val=0\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_running_loss=0\n",
    "        val_running_loss=0\n",
    "        train_running_acc=0\n",
    "        val_running_acc=0\n",
    "\n",
    "\n",
    "        #training\n",
    "        model.train()\n",
    "        for images , labels in train_data_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            model_out=model(images)\n",
    "            model_out= F.log_softmax(model_out, dim=1)\n",
    "\n",
    "            loss= criterion(model_out,labels)\n",
    "\n",
    "            train_running_loss += loss.item() #to sum up the loss generated in each batch\n",
    "            loss.backward()  #\n",
    "            optimizer.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()    # change into evaluation mode\n",
    "        for images , labels in train_data_loader:\n",
    "            # print(images.shape, labels.shape)\n",
    "\n",
    "            model_out=model(images)\n",
    "            model_out= F.log_softmax(model_out, dim=1)\n",
    "\n",
    "            #for accuracy\n",
    "            preds = torch.argmax(model_out,dim=1)\n",
    "            acc = (preds==labels).float().mean()  #running accuracy\n",
    "            train_running_acc += acc.item()\n",
    "\n",
    "\n",
    "        for images , labels in val_data_loader:\n",
    "            # print(images.shape, labels.shape)\n",
    "\n",
    "            model_out=model(images)\n",
    "            model_out= F.log_softmax(model_out, dim=1)\n",
    "\n",
    "            #for accuracy\n",
    "            preds = torch.argmax(model_out,dim=1)\n",
    "            acc = (preds==labels).float().mean()  #running accuracy\n",
    "            val_running_acc += acc.item()\n",
    "\n",
    "            loss= criterion(model_out,labels)\n",
    "            val_running_loss += loss.item() #to sum up the loss\n",
    "\n",
    "        #losses\n",
    "        avg_train_loss= train_running_loss/len(train_data_loader) #total loss minus no of batch\n",
    "        avg_val_loss= val_running_loss/len(val_data_loader) #total loss minus no of batch\n",
    "\n",
    "\n",
    "        epochwise_train_losses.append(avg_train_loss)\n",
    "        epochwise_val_losses.append(avg_val_loss)\n",
    "\n",
    "\n",
    "        #accuracy\n",
    "        avg_train_acc= train_running_acc/len(train_data_loader)\n",
    "        avg_val_acc= val_running_acc/len(val_data_loader)\n",
    "\n",
    "        epochwise_val_acc.append(avg_val_acc)\n",
    "\n",
    "\n",
    "        #log to tensorboard\n",
    "\n",
    "        writer.add_scalar(\"Loss/Train\",avg_train_loss,epoch)\n",
    "        writer.add_scalar(\"loss/Val\",avg_val_loss,epoch)\n",
    "        writer.add_scalar(\"Accuracy/Train\",avg_train_acc,epoch)\n",
    "        writer.add_scalar(\"Accuracy/Val\",avg_val_acc,epoch)\n",
    "        #early stopping criteria\n",
    "        if (epoch >= MIN_EPOCH):\n",
    "            last_5_val_avg = np.mean(epochwise_val_acc[-5:])\n",
    "            first_5_val_avg = np.mean(epochwise_val_acc[-6:-1])\n",
    "            diff= last_5_val_avg - first_5_val_avg\n",
    "            if diff < 0.001:\n",
    "                break\n",
    "\n",
    "        print(f\"Epoch{epoch} Train Loss:{avg_train_loss:.3f}\\t train_accuracy:{avg_train_acc:.2f} \\t Val Loss:{avg_val_loss:.2f} \\t val_accuracy:{avg_val_acc:.2f}\")\n",
    "\n",
    "\n",
    "        checkpoint_name=f\"artifacts/{folder_name}/ckpt--{model.__class__.__name__}--val-acc-{avg_val_acc:.2f}--epoch-{epoch}.pth\"\n",
    "        checkpoint={\n",
    "            \"epoch\":epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"train_loss\":avg_train_loss,\n",
    "            \"val_loss\":avg_val_loss,\n",
    "            \"train_acc\":avg_train_acc,\n",
    "            \"val_acc\":avg_val_acc\n",
    "        }\n",
    "        #save the model\n",
    "        # torch.save(checkpoint,checkpoint_name)\n",
    "        # if avg_val_acc>best_val:\n",
    "        #     best_val=avg_val_acc\n",
    "        #     torch.save(model.state_dict(),f\"artifacts/{folder_name}/--best-model-val-acc-.pth\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #plot the losses and accuracy\n",
    "    # fig,(ax1,ax2)= plt.subplots(1,2,figsize=(16,9))\n",
    "    # x_axis_values = np.arange(0,epoch + 1,1)\n",
    "\n",
    "    # ax1.plot(x_axis_values,epochwise_train_losses,label=\"train_loss\")\n",
    "    # ax1.plot(x_axis_values,epochwise_val_losses,label=\"val_loss\")\n",
    "    # ax1.set_title(\"Train Losses v/s validation Losses\")\n",
    "    # ax1.legend()\n",
    "\n",
    "    # ax2.plot(x_axis_values,epochwise_train_acc,label=\"train_acc\")\n",
    "    # ax2.plot(x_axis_values,epochwise_val_acc,label=\"val_acc\")\n",
    "    # ax2.set_title(\"Train accuracy v/s validation accuracy\")\n",
    "    # ax2.legend()\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    #load model\n",
    "\n",
    "    # model.load_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJ6VKGd0of0P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5Tf2NvVjBYH"
   },
   "outputs": [],
   "source": [
    "#train.py\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from os.path import join\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from utils.io import read_as_csv\n",
    "from utils.preprocessing import read_image, image_transforms,label_transform\n",
    "from utils.preprocessing import label_to_index\n",
    "from config import MODEL_CHECKPOINT_PATH, ROOT_DIR\n",
    "\n",
    "##these are the datapoints grouped.\n",
    "#load csv\n",
    "train_files, train_labels= read_as_csv(\"data/train.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x_train= [ image_transforms(filename,label,root_dir=ROOT_DIR) for filename,label in zip(train_files,train_labels)]\n",
    "\n",
    "    y_train=[label_transform(label) for label in train_labels ]\n",
    "\n",
    "    clf= KNeighborsClassifier(n_neighbors=4)\n",
    "    clf.fit(x_train,y_train)\n",
    "    print(\"The train score is:\",clf.score(x_train,y_train))\n",
    "\n",
    "    # save model\n",
    "    with open (MODEL_CHECKPOINT_PATH,'wb') as file:\n",
    "        pickle.dump(clf,file)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmbwLHhHjGeG"
   },
   "outputs": [],
   "source": [
    "#evaluate.py\n",
    "\n",
    "#import checkpoint\n",
    "\n",
    "from config import MODEL_CHECKPOINT_PATH, ROOT_DIR\n",
    "from utils.io import read_as_csv, save_as_csv,read_predictions\n",
    "import pickle\n",
    "import yaml\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.preprocessing import label_to_index, image_transforms,label_transform,label_index,index_label\n",
    "from viz.display_image_grid import display_grid\n",
    "from utils.load_config import config_loader\n",
    "from app import predict\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_predictions(model_checkpoint,test_file, out_dir):\n",
    "\n",
    "    #load the model using\n",
    "    with open (model_checkpoint,'rb') as file:\n",
    "        model=pickle.load(file)\n",
    "\n",
    "    test_filename, test_labels= read_as_csv(test_file)\n",
    "\n",
    "    LABELS = label_index.keys()\n",
    "    #predict on test data and save it somewhere\n",
    "    x_test= [ image_transforms(filename,label,root_dir = \"data/genetic-syndrome-dataset\") for filename,label in zip(test_filename, test_labels)]\n",
    "    y_test=[label_transform(label) for label in test_labels ]\n",
    "    y_pred= model.predict(x_test)\n",
    "    y_pred_labels=[ index_label[y_pred_index] for y_pred_index in y_pred ]\n",
    "    # print(y_pred_labels)\n",
    "    save_as_csv(test_filename, test_labels, out_dir,y_pred_labels)\n",
    "\n",
    "\n",
    "##\n",
    "def evaluate(out_directory):\n",
    "    file_name,label,pred_label= read_predictions(out_directory)\n",
    "    y_test=[label_transform(label) for label in label ]\n",
    "    y_pred= [label_transform(pred_label) for y_pred_index in pred_label ]\n",
    "    print(y_test,y_pred)\n",
    "\n",
    "\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    # outdir= 'results/predictions.csv'\n",
    "    configs= config_loader(\"configs\\evaluate_configs.yaml\")\n",
    "    # get_predictions(configs.get(\"checkpoint_path\"),configs.get(\"test_csv\"),configs.get(\"out_dir\"))\n",
    "    # read_predictions(configs.get(\"out_dir\"))\n",
    "    evaluate(configs.get(\"out_dir\"))\n",
    "\n",
    "    # y_pred= model.predict(x_test)\n",
    "    # cm = confusion_matrix(y_test, y_pred)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=LABELS)\n",
    "    #\n",
    "    # print(LABELS) neede=s to be uncomment\n",
    "    # print(cm)\n",
    "    # disp.plot()\n",
    "\n",
    "    # plt.show()\n",
    "    # print(\"The test score is:\", model.score(x_test,y_test))\n",
    "\n",
    "    # print(\"y predict\",y_pred)\n",
    "    # print(classification_report(y_true=y_test, y_pred=y_pred, target_names=LABELS))\n",
    "\n",
    "    # print(display_grid(ROOT_DIR,test_filename, test_labels,3,4,'Genetic Syndrome',y_pred_labels))  till here\n",
    "\n",
    "    # target_names=['']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #score print score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMmiJbTmjNtG"
   },
   "outputs": [],
   "source": [
    "#app.py\n",
    "\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import gradio as gr\n",
    "import torch.nn as nn\n",
    "import  torch.nn.functional\n",
    "import torchvision.transforms as T\n",
    "from models.customNN import FirstAttemptFCN, Model\n",
    "from utils.io import read_as_csv\n",
    "\n",
    "\n",
    "model_path= r\"artifacts\\run-2023-11-29-16-14-49\\ckpt--FirstAttemptFCN--val-acc-0.72--epoch-1.pth\"\n",
    "checkpoint= torch.load(model_path)\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "model= FirstAttemptFCN(img_size=256, num_channels=3,num_labels=5)\n",
    "# model.load_state_dict(model_state_dict)\n",
    "model.eval()\n",
    "# print(checkpoint)\n",
    "transform= T.Compose([T.Resize(size = (256,256)), T.ToTensor()])\n",
    "\n",
    "labels=[\"Angleman\", \"apert\", \"charge\", \"down\", \"williams\",\"Cannot identify\"]\n",
    "def predict(inp):\n",
    "  inp = transform(inp).unsqueeze(0)\n",
    "  with torch.no_grad():\n",
    "\n",
    "    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n",
    "\n",
    "    confidences = {labels[i]: float(prediction[i]) for i in range(prediction.shape[0])}\n",
    "    # max= list(sorted(confidences.values()))[-1]\n",
    "    # second_max= list(sorted(confidences.values()))[-2]\n",
    "    # if(max-second_max>0.9):\n",
    "    #   return(confidences)\n",
    "    # else:\n",
    "    #   return('cannot identify')\n",
    "\n",
    "\n",
    "  # return confidences, prediction\n",
    "  return confidences\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gr.Interface(fn=predict,\n",
    "             inputs=gr.Image(type=\"pil\"),\n",
    "             outputs=gr.Label(num_top_classes=5),\n",
    "             examples=[r\"data\\genetic-syndrome-dataset\\AngleMan\\ndl4wvs.jpg\",\n",
    "                       r\"data\\genetic-syndrome-dataset\\charge\\charge 5.jpg\",\n",
    "\n",
    "             ]\n",
    ").launch()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bw_toUFjjYgX"
   },
   "outputs": [],
   "source": [
    "#preprocessing.py\n",
    "\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.io import get_image_label_pairs\n",
    "from utils.io import list_files\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "def image_transforms(filename,label,root_dir):\n",
    "    ##since the image is inside the folder so we first join dir filename\n",
    "    ##then we finally join all to get the required path\n",
    "    \"\"\" Extracts the image from the file name and label\n",
    "        filename:string\n",
    "        label:string\n",
    "        root_dir: string \"\"\"\n",
    "    file_path = os.path.join(root_dir,label, filename)\n",
    "\n",
    "    ##we perform required transforms\n",
    "\n",
    "    img_arr=read_image(file_path, mode=\"zoom\",size=(64,64),grayscale=True)\n",
    "    flattened_img_arr= img_arr.flatten()\n",
    "    # print(flattened_img_arr.shape)\n",
    "    return flattened_img_arr\n",
    "\n",
    "def label_transform(label):\n",
    "    index= label_to_index(label)\n",
    "    return index\n",
    "def read_image(image_path:str,mode:str, size=(100,100), grayscale:bool=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    TODO: resize to a default value\n",
    "    args:\n",
    "    -------\n",
    "    image_path: str filepath of the image we want to read.\n",
    "    mode: str should be either zoom or padding, this argument basically defines either zoom or padding at the border.\n",
    "    size: tuple that consists width and height\n",
    "    \"\"\"\n",
    "\n",
    "    with Image.open(image_path) as im:\n",
    "        width,height= im.size\n",
    "        changed_image = im\n",
    "        if width!=height:\n",
    "            #if the size is not same, we are trying to make the size same , either by zoom or padding .\n",
    "            #  After the size is equl , resizing is done.\n",
    "            if mode=='zoom':\n",
    "                 if(width>height):\n",
    "                    #we need to cut from the width\n",
    "                    crop_size=(width-height)/2\n",
    "                    left, top, right, bottom = crop_size,0,width-crop_size,height\n",
    "                    changed_image=im.crop((left, top, right, bottom))\n",
    "                    # print('after cropping',changed_image.size)\n",
    "                 else:\n",
    "                    #we need to cut from the height\n",
    "                    crop_size=(height-width)/2\n",
    "                    left, top, right, bottom =  0, crop_size  ,width, height-crop_size\n",
    "                    changed_image=im.crop((left, top, right, bottom))\n",
    "                    # print('after cropping',cropped_image.size)\n",
    "\n",
    "            elif mode=='padding':\n",
    "                   changed_image= ImageOps.pad(im,size)\n",
    "                #    print()\n",
    "\n",
    "\n",
    "        resized_image = changed_image.resize(size,resample=0).convert(\"RGB\")\n",
    "        img1_array=np.asarray(resized_image)\n",
    "        # print(img1_array)\n",
    "        return(img1_array)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def display_grid(image_dir,images,labels: list,n_rows:int,n_cols:int,title:str):\n",
    "#     fig,axes = plt.subplots(n_rows,n_cols)\n",
    "#     fig.suptitle(title)\n",
    "#     idx=0\n",
    "#     for i in range(n_rows):\n",
    "#             for j in range(n_cols):\n",
    "\n",
    "#                 image_list =join(IMAGE_DIR,image_file_name[idx])\n",
    "\n",
    "#                 img_arr = read_image(image_list,mode='padding',size=(100,100),grayscale=True)\n",
    "#                 axes[i][j].imshow(img_arr)\n",
    "#                 axes[i][j].set_title(f\"label: {labels[idx]}\")\n",
    "#                 axes[i][j].set_xticks([])\n",
    "#                 axes[i][j].set_yticks([])\n",
    "#                 idx+= 1\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "label_index = { 'AngleMan':0, 'Apert': 1,'charge':2, 'Down':3,'Williams':4}\n",
    "index_label = {index:label for label, index in label_index.items()}\n",
    "\n",
    "\n",
    "def label_to_index(label):\n",
    "    try:\n",
    "        return label_index[label]\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"Label:{label} not found try one of these: {list(label_index.keys())}\")\n",
    "\n",
    "def index_to_label(index):\n",
    "     try:\n",
    "        return(index_label[index])\n",
    "     except KeyError:\n",
    "         raise KeyError(f\"Index not found try one of these: {list(index_label.keys())}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # print(\"hello from preprocessing\")\n",
    "\n",
    "    # IMAGE_PATH = r'data\\genetic-syndrome-dataset\\Apert\\njug98f.jpg'\n",
    "    # image = read_image(IMAGE_PATH)\n",
    "\n",
    "    # plt.imshow(image)\n",
    "    # #removeticks\n",
    "    # plt.xticks([])\n",
    "    # plt.yticks([])\n",
    "\n",
    "\n",
    "    # #add title#plot image\n",
    "    # plt.title(\"Apert Syndrome\")\n",
    "\n",
    "    from viz.display_image_grid import display_grid\n",
    "    IMAGE_DIR=\"data\\genetic-syndrome-dataset\\Apert\"\n",
    "    imggg_path,labels = get_image_label_pairs(IMAGE_DIR, 'Apert')\n",
    "\n",
    "\n",
    "    image_file_name= list_files(IMAGE_DIR,'')\n",
    "    # ###to print label to index\n",
    "    # print(label_to_index(\"Apert\"))\n",
    "    # # ##to print index to label\n",
    "    # print(index_to_label(66))\n",
    "\n",
    "\n",
    "    display_grid(IMAGE_DIR,image_file_name,labels,3,4,'Genetic Syndrome')\n",
    "\n",
    "\n",
    "    # sample_img_path =r'data\\genetic-syndrome-dataset\\Apert\\pl8tkd4.jpg'\n",
    "    # sample_img_path_2 =r'data\\genetic-syndrome-dataset\\Apert\\qh5g95a.jpg'\n",
    "\n",
    "    # img = Image.open(sample_img_path_2)\n",
    "    # print('original image size',img.size)\n",
    "    # img = read_image(image_path=sample_img_path_2,mode='zoom')\n",
    "    # print(img.shape)\n",
    "    # # plt.imshow(img)\n",
    "    # plt.show()\n",
    "    ##dictionary for label and index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EnVHdqspsUO"
   },
   "outputs": [],
   "source": [
    "#visualizing\n",
    "\n",
    "from config import MODEL_CHECKPOINT_PATH\n",
    "import pickle\n",
    "from utils.io import read_as_csv\n",
    "from utils.preprocessing import image_transforms,label_transform,read_image\n",
    "from utils.io import read_as_csv\n",
    "from config import MODEL_CHECKPOINT_PATH, ROOT_DIR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "with open (MODEL_CHECKPOINT_PATH,'rb') as file:\n",
    "    model=pickle.load(file)\n",
    "test_filename, test_labels= read_as_csv(\"data/test.csv\")\n",
    "x_test= [ image_transforms(filename,label,root_dir = \"data/genetic-syndrome-dataset\")\n",
    "         for filename,label in zip(test_filename, test_labels)]\n",
    "\n",
    "train_files, train_labels= read_as_csv(\"data/train.csv\")\n",
    "x_train= [ image_transforms(filename,label,root_dir=ROOT_DIR)\n",
    "           for filename,label in zip(train_files,train_labels)]\n",
    "\n",
    "y_train=[label_transform(label) for label in train_labels ]\n",
    "\n",
    "graph=model.kneighbors(x_test[:4],n_neighbors=5,return_distance=False)\n",
    "print(graph)\n",
    "print(type(graph))\n",
    "\n",
    "fig, axes = plt.subplots(4,6 ,figsize=(10, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    axes[i, 0].imshow(x_test[i].reshape(64, 64,3))\n",
    "    axes[i, 0].set_title(f\"Test Image {i+1}\")\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    for j, idx in enumerate(graph[i]):\n",
    "        axes[i, j+1].imshow(x_train[idx].reshape(64, 64,3))\n",
    "        axes[i, j+1].axis('off')\n",
    "        axes[i, j+1].set_title(f\"nearest neighbors {j}\")\n",
    "\n",
    "\n",
    "#     file_path = os.path.join(root_dir,label, filename)\n",
    "#     img_arr=read_image(file_path, mode=\"zoom\",size=(64,64),grayscale=True)\n",
    "#     flattened_img_arr= img_arr.flatten()\n",
    "#     return flattened_img_arr\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dM4Im_Xwpymm"
   },
   "outputs": [],
   "source": [
    "#requirement.txt\n",
    "numpy\n",
    "scikit-learn==1.2.1\n",
    "matplotlib==3.7.2\n",
    "torch\n",
    "torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGtRU83Uog_G"
   },
   "outputs": [],
   "source": [
    "#io.py\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "def list_files(dir: str, file_extension: str) -> list:\n",
    "    if not os.path.isdir(dir):\n",
    "        return None\n",
    "    files = os.listdir(dir)\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_image_label_pairs(images_path: str, label: str):\n",
    "    image_file_names = list_files(images_path, \"jpg\")\n",
    "    label_name = [label] * len(image_file_names)\n",
    "    return (image_file_names, label_name)\n",
    "\n",
    "# def read_as_csv(image_paths, labels, outfile):\n",
    "#     with open(outfile,\"r\")\n",
    "\n",
    "def save_as_csv(image_paths, labels, outfile,pred_lables=None):\n",
    "    with open(outfile, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        if pred_lables:\n",
    "            writer.writerow([\"file\", \"label\",\"predicted_labels\"])\n",
    "\n",
    "            for image_path, label, pred_lables in zip(image_paths, labels,pred_lables):\n",
    "                writer.writerow([image_path, label,pred_lables])\n",
    "        else:\n",
    "            writer.writerow([\"file\", \"label\",\"predicted_labels\"])\n",
    "\n",
    "            for image_path, label in zip(image_paths, labels,pred_lables):\n",
    "                writer.writerow([image_path, label])\n",
    "def read_as_csv(csv_path):\n",
    "    file_name_arr=[]\n",
    "    label_arr=[]\n",
    "    with open(csv_path,'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "             file_name_arr.append(row[0])\n",
    "             label_arr.append(row[1])\n",
    "        return(file_name_arr,label_arr)\n",
    "\n",
    "def read_predictions(csv_path):\n",
    "    file_name_arr=[]\n",
    "    label_arr=[]\n",
    "    pred_label_arr=[]\n",
    "    with open(csv_path,'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "             file_name_arr.append(row[0])\n",
    "             label_arr.append(row[1])\n",
    "             pred_label_arr.append(row[2])\n",
    "        return(file_name_arr,label_arr,pred_label_arr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # z=list_files('data\\genetic-syndrome-dataset\\AngleMan','jpg')\n",
    "    # print(z)\n",
    "    # images_1,labels_1 =get_image_label_pairs('data\\genetic-syndrome-dataset\\AngleMan','Angleman')\n",
    "    # images_2,labels_2 =get_image_label_pairs('data\\genetic-syndrome-dataset\\Apert','Apert')\n",
    "\n",
    "    # save_as_csv(images_1,labels_1,'data/Angleman.csv')\n",
    "    # save_as_csv(images_2,labels_2,'data/Apert.csv')\n",
    "\n",
    "    # img_folders = [\"Angleman\", \"apert\", \"charge\", \"down\", \"williams\"]\n",
    "    # x = []\n",
    "    # y = []\n",
    "    # for image in img_folders:\n",
    "    #     image_path = f\"data\\genetic-syndrome-dataset\\{image}\"\n",
    "    #     images, labels = get_image_label_pairs(image_path, image)\n",
    "    #     x.extend(images)\n",
    "    #     y.extend(labels)\n",
    "\n",
    "    # # save_as_csv= f'{x},{y},'data/.csv'\n",
    "    # save_as_csv(x, y, \"data/genetics_entire.csv\")\n",
    "\n",
    "\n",
    "    ##gives us diffrent column of file name and label\n",
    "   file_name, label=read_as_csv(\"'data/test.csv'\",\"data/train.csv\")\n",
    "#    print(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjMySNBAoi5e"
   },
   "outputs": [],
   "source": [
    "#prepare dataset\n",
    "import glob\n",
    "from utils.io import get_image_label_pairs\n",
    "from utils.io import save_as_csv\n",
    "\n",
    "BASE_DIR= 'data\\Ear Domain\\Datos'\n",
    "TEST_DIR= ' data\\Ear Domain\\Datos\\Testing'\n",
    "TRAIN_DIR = 'data\\Ear Domain\\Datos\\Training-validation'\n",
    "img_folder_name= ['Chronic otitis media','Earwax plug','Myringosclerosis','Normal']\n",
    "train_images=glob.glob(f\"{TRAIN_DIR}/**/*.jpg\")\n",
    "test_images=glob.glob(f\"{TEST_DIR}/**/*.jpg\")\n",
    "\n",
    "# print(train_label)\n",
    "train_label=[label.split(\"//\")[:4] for label in train_images]\n",
    "test_label=[label.split(\"//\")[:4] for label in test_images]\n",
    "\n",
    "save_as_csv(train_images, train_label, \"data/Ear Domain/Datos/train.csv\")\n",
    "save_as_csv(test_images, test_label, \"data/Ear Domain/Datos/test.csv\")\n",
    "# x = []\n",
    "# y = []\n",
    "# for image in img_folder_name:\n",
    "#         image_path = f\"data\\Ear Domain\\Datos\\Testing{image}\"\n",
    "#         images, labels = get_image_label_pairs(image_path, image)\n",
    "#         x.extend(images)\n",
    "#         y.extend(labels)\n",
    "\n",
    "# save_as_csv(x, y, \"data/Ear Domain/Datos/test.csv\")\n",
    "# for image in img_folder_name:\n",
    "#         image_path = f\"data\\Ear Domain\\Datos\\Training-validation{image}\"\n",
    "#         images, labels = get_image_label_pairs(image_path, image)\n",
    "#         x.extend(images)\n",
    "#         y.extend(labels)\n",
    "\n",
    "    # save_as_csv= f'{x},{y},'data/.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dT2suwEqoyrO"
   },
   "outputs": [],
   "source": [
    "#traintestsplit\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from os.path import join\n",
    "from utils.io import get_image_label_pairs\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from utils.io import save_as_csv\n",
    "# DATA_DIR = 'data\\genetic-syndrome-dataset'\n",
    "#using argparse\n",
    "\n",
    "#creating an instance of class Argumentparser\n",
    "parser= argparse.ArgumentParser(prog='')\n",
    "parser.add_argument(\"-d\",'--data_dir',type=str, help='Consist path of the images in directory')\n",
    "# parser.add_argument('--label',action= 'append', help='list of the name of labels from the folder')\n",
    "parser.add_argument('--test_size',type=float, help='test size of the train and test')\n",
    "parser.add_argument('--random_state',type=int, help='random_slate of the train and test')\n",
    "\n",
    "args= parser.parse_args()\n",
    "\n",
    "print(args.data_dir)\n",
    "DATA_DIR= args.data_dir\n",
    "\n",
    "data_folders = os.listdir(DATA_DIR)\n",
    "\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "for folder in data_folders:\n",
    "    data_path = join(DATA_DIR,folder)\n",
    "    label=folder\n",
    "\n",
    "    files_name,labels= get_image_label_pairs(data_path, label)\n",
    "    X.extend(files_name)\n",
    "    Y.extend(labels)\n",
    "\n",
    "print(len(X),len(Y))\n",
    "\n",
    "#split the data into train and test sets\n",
    "\n",
    "X_test, X_train, Y_test, Y_train = train_test_split(X,Y,test_size=0.20,random_state=42)\n",
    "print(\"X test size:\", len(X_test))\n",
    "print(\"Y test size:\", len(Y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# save_as_csv(X_test,Y_test,'data/test.csv')\n",
    "# save_as_csv(X_train,Y_train,'data/train.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jig5AHhpA0u"
   },
   "outputs": [],
   "source": [
    "#image dataset\n",
    "from utils.preprocessing import read_image, image_transforms,label_transform\n",
    "from utils.preprocessing import label_to_index\n",
    "from utils.io import read_as_csv\n",
    "from config import MODEL_CHECKPOINT_PATH, ROOT_DIR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GeneticDataset(Dataset):\n",
    "    def __init__(self,csv_file):\n",
    "        train_files, train_labels= read_as_csv(csv_file)\n",
    "        self.imgs= [ image_transforms(filename,label,root_dir=ROOT_DIR) for filename,label in zip(train_files,train_labels)]\n",
    "        self.labels=[label_transform(label) for label in train_labels ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index=0):\n",
    "        # return self.imgs[index],self.labels[index]\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,csv_path,transforms:None):\n",
    "        images,labels=read_as_csv(csv_path)\n",
    "        self.images = images\n",
    "        self.labels=labels\n",
    "        self.transforms=transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<ImageDataset with {self.__len__()} samples>\"\n",
    "    def __getitem__(self,index):\n",
    "        # image=self.images[index]\n",
    "        # label=self.labels[index]\n",
    "        image_name=self.images[index]\n",
    "        label_name= self.labels[index]\n",
    "\n",
    "        image_path= join(\"data\",\"genetic-syndrome-dataset\",label_name,image_name)\n",
    "        image= Image.open(image_path).convert('RGB')\n",
    "        label=label_to_index(label_name)\n",
    "        if self.transforms:\n",
    "            image= self.transforms(image)\n",
    "        return image,label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHnl4U7vpI83"
   },
   "outputs": [],
   "source": [
    "#configs.yaml\n",
    "data_root: data\n",
    "train_csv: train1.csv\n",
    "test_csv: test1.csv\n",
    "models:\n",
    "  name: kneighbors\n",
    "  args:\n",
    "      n_neighbors: 3\n",
    "checkpoint_path: models/finalized_knn_model.sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMcVaO7MpkqO"
   },
   "outputs": [],
   "source": [
    "#load config\n",
    "import yaml\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "\n",
    "def config_loader(config_file):\n",
    "    config={}\n",
    "    with open(config_file,\"r\")as stream:\n",
    "        try:\n",
    "            config = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsCmAVZYpNX-"
   },
   "outputs": [],
   "source": [
    "#evaluateconfigs\n",
    "\n",
    "data_root: data\n",
    "train_csv: train1.csv\n",
    "test_csv: test1.csv\n",
    "out_dir: results/predictions.csv\n",
    "checkpoint_path: models/knn_model.pkl\n",
    "test_csv: 'data/test.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jr1LWisBpUXW"
   },
   "outputs": [],
   "source": [
    "#model\n",
    "import torch\n",
    "from torch.nn.functional import relu\n",
    "from torch.nn import Linear\n",
    "import torch.nn as nn\n",
    "\n",
    "class FirstAttemptFCN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    subclassing torch.nn.module gives\n",
    "      us automatic gradient calculation\n",
    "\n",
    "    Args:\n",
    "        torch (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size:int, num_channels,num_labels) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1=Linear(img_size*img_size*num_channels,128)\n",
    "        self.fc2=Linear(128, num_labels)\n",
    "\n",
    "    def forward(self,x: torch.tensor):\n",
    "        x=x.reshape(x.shape[0], -1)\n",
    "        return self.fc2(relu(self.fc1(x)))\n",
    "\n",
    "class SecondAttemptFCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,img_size:int,num_labels):\n",
    "        super().__init__()\n",
    "        # self.fc21= Linear(img_size*img_size,512)\n",
    "        # self.fc22= Linear(512,256)\n",
    "        # self.fc23 =Linear(256,128)\n",
    "        # self.fc24 =Linear(256,num_labels)\n",
    "        self.nn= torch.nn.Sequential(\n",
    "            Linear(img_size*img_size,512),\n",
    "            torch.nn.ReLU(),\n",
    "            Linear(512,128),\n",
    "            torch.nn.ReLU(),\n",
    "            Linear(128,num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x:torch.tensor):\n",
    "        x=x.reshape(-1)\n",
    "        return self.nn(x)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3,3,kernel_size=3,padding=1)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_1 = nn.Conv2d(3,1,kernel_size=3,padding=1)\n",
    "        self.linear_1=nn.Linear(1*32*32,4)\n",
    "        # self.linear_2 = nn.Linear(10,2)\n",
    "        # self.softmax=nn.Softmax()\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=  self.conv(x)\n",
    "        x=  self.max_pool(x)\n",
    "        x=  self.conv(x)\n",
    "        x=  self.max_pool(x)\n",
    "        x=  self.conv_1(x)\n",
    "        x=  self.max_pool(x)\n",
    "        x=self.linear_1(x.view(1,-1))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
